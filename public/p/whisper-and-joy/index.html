<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Whisper and Joy | A blog by Yosua Ian Sebastian</title><meta name=keywords content="gkms,100DaysToOffload"><meta name=description content="I should write more about the makings of my dumb side project before it gets shelved and never written about again."><meta name=author content="Yosua"><link rel=canonical href=https://darcien.dev/p/whisper-and-joy/><link crossorigin=anonymous href=/assets/css/stylesheet.af4641ce48a747a666fc5670ecf1ca0b28f7fbaad47ea6f82ebf08649e6b028a.css integrity="sha256-r0ZBzkinR6Zm/FZw7PHKCyj3+6rUfqb4Lr8IZJ5rAoo=" rel="preload stylesheet" as=style><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=2"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=2"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=2"><link rel=manifest href="/site.webmanifest?v=2"><link rel=mask-icon href="/safari-pinned-tab.svg?v=2" color=#34343c><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><link rel=alternate hreflang=en href=https://darcien.dev/p/whisper-and-joy/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link crossorigin=anonymous href=/style.css rel="preload stylesheet" as=style><meta property="og:url" content="https://darcien.dev/p/whisper-and-joy/"><meta property="og:site_name" content="A blog by Yosua Ian Sebastian"><meta property="og:title" content="Whisper and Joy"><meta property="og:description" content="I should write more about the makings of my dumb side project before it gets shelved and never written about again."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="p"><meta property="article:published_time" content="2025-07-15T21:04:00+10:00"><meta property="article:modified_time" content="2025-07-15T21:04:00+10:00"><meta property="article:tag" content="Gkms"><meta property="article:tag" content="100DaysToOffload"><meta name=twitter:card content="summary"><meta name=twitter:title content="Whisper and Joy"><meta name=twitter:description content="I should write more about the makings of my dumb side project before it gets shelved and never written about again."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Ps","item":"https://darcien.dev/p/"},{"@type":"ListItem","position":2,"name":"Whisper and Joy","item":"https://darcien.dev/p/whisper-and-joy/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Whisper and Joy","name":"Whisper and Joy","description":"I should write more about the makings of my dumb side project before it gets shelved and never written about again.","keywords":["gkms","100DaysToOffload"],"articleBody":" 🔖 Assumed post audience: me. This is not a tutorial for whisper.cpp. I am writing up my usage, and if I don’t write it now, I’ll never write about it.\nI want to analyze the words used in an internet radio series. It’s for a dumb side project.\nI already heard about Whisper from OpenAI before. And I finally have the justification to try it out.\nAttempt 1 - insanely fast whisper I don’t remember why, but I started with insanely fast whisper instead of the official Whisper repo. Probably drawn in by the name, who doesn’t like insanely fast stuff.\nAttempt didn’t last long though. I followed the readme and used pipx. And it failed on building sentencepiece with no clear error message.\nI tried again with uv tool install. It failed again on sentencepiece, but gave a better message around the minimum CMake version. Unfortunately, I already have latest CMake via Homebrew.\nA quick search turned up various people, each with different setups and different errors.\nGreat.\nIt’s 2025 and Python ecosystem is still as messy as ever. I didn’t miss it at all.\nAttempt 2 - MacWhisper I found MacWhisper in a GH discussion. Looks like a clean and simple macOS app with no python mess, let’s try it.\nIt’s free, and I’m grateful for that. But oof, on start, it downloads the v3 turbo model. It immediately runs transcription on my CPU on file selection. And then say it says it’s requires pro license.\n100 EUR for permanent license.\nOk, time to try something else. Sorry, not a fan of that default behavior of wasting bandwidth and CPU before asking for money. I lost my interest even before retrying with “free” model.\nAttempt 3 - whisper.cpp I’m going to start with: no dependencies is awesome. That’s whisper.cpp.\nI cheated a bit and installed via Homebrew though.\nbrew install whisper-cpp Next, model. My radio series is in Japanese. I can’t find any mainstream JP model. So I went with large-v3-turbo.\nThere are quantized models (q5 and q8 at the time). But doesn’t seem to provide any savings in my case. I have enough RAM to load the large model (~3.9 GB) and the disk savings are \u003c 1 GB.\nwhisper.cpp provided nice script to download the model:\n./download-ggml-model.sh large-v3-turbo Next, preparing the audio input.\nPreparing the audio Note that the whisper-cli example currently runs only with 16-bit WAV files, so make sure to convert your input before running the tool. For example, you can use ffmpeg like this:\nffmpeg -i input.mp3 -ar 16000 -ac 1 -c:a pcm_s16le output.wav Okay, my source is an mp4 container. How can I convert it to WAV?\nThat was a dumb question. ffmpeg is just too awesome, you can throw the mp4 at it directly.\nSo my command is exactly the same as the example from whisper.cpp.\nTest run with whisper.cpp Ooohhhh it runs on metal, literally!\n❯ whisper-cli -m ./ggml-large-v3-turbo.bin --detect-language -f housoubu/45_f5t3gjlf9we.wav whisper_init_from_file_with_params_no_state: loading model from './ggml-large-v3-turbo.bin' ... system_info: n_threads = 4 / 10 | WHISPER : COREML = 0 | OPENVINO = 0 | Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | ACCELERATE = 1 | REPACK = 1 | main: processing 'housoubu/45_f5t3gjlf9we.wav' (44800341 samples, 2800.0 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = auto, task = transcribe, timestamps = 1 ... whisper_full_with_state: auto-detected language: ja (p = 0.998406) ... ggml_metal_free: deallocating I’m using --detect-language just for sanity check, but it’s looking great!\n-dl, --detect-language [false] exit after automatically detecting language Onwards to the real test run! I tested with default parameters, and the live output looks great.\nUntil I saw this:\n[00:33:06.200 --\u003e 00:33:08.520] シン・スミカでラブ\u0026ジョイ [00:33:08.920 --\u003e 00:33:30.900] さよならを告げた後悔 [00:33:30.900 --\u003e 00:33:32.900] さよならを告げてください [00:33:32.900 --\u003e 00:33:33.900] さよならを告げてください [00:33:33.900 --\u003e 00:33:34.900] さよならを告げてください ... [00:36:25.900 --\u003e 00:36:27.900] さよならを告げてください [00:36:27.900 --\u003e 00:36:29.900] さよならを告げてください [00:36:29.900 --\u003e 00:36:30.900] さよならを告げてください [00:36:30.900 --\u003e 00:36:33.900] 7月4日の公演をもって完走した Looks very scary at first, like one of those horror movies where paranormal activities start to spam you with the same message over and over. Even more so when model changed the lyric from “さよならを告げた 後悔” to “さよならを告げてください”. Literally translated, it’s “I said goodbye. Regret” changed to “Please say goodbye”.\nSo what I have now is:\nPlease say goodbye Please say goodbye Please say goodbye ... Please say goodbye Please say goodbye Please say goodbye 😱😱😱\nBut I already listened to that episode. I know nobody is repeating that same sentence for 3 minutes straight.\nActual lyrics are1:\nさよならを告げた 後悔 一歩ずつ前へ進んでも まだ隠してる弱さは見せれない The model did get the first sentence correct. But the song already stopped playing at 34:50 mark. Another sentence already started from 34:55 and it still outputs the same goodbye sentence. So model lost track of at least ~1.5 minutes worth of conversation here.\nThis audio section might be a good test input while I do trial and error with the transcription. It shouldn’t be censorship that prevents transcribing licensed music right? I sure hope we’re not at that point of dystopia yet.\nWhat’s next? I need to optimize whisper parameters to fit my use case. Probably manually for now since the radio episode isn’t that long, ~46 mins each.\nAlso need to download only the audio part as the radio video is mostly static and irrelevant in this case. Probably yt-dlp -x works here.\nAfterthought I’m not sure what is this weird feeling. The “standing on the shoulder of giants” feeling, maybe awe? It’s mindblowing that I could just piece around few open source building blocks in a few hours, and have a working implementation for video -\u003e audio -\u003e text. And it’s for non-English content!\nFew years ago, I feel like this would take me maybe months to read and implement someone’s PhD thesis. I wouldn’t have the time to do that for a dumb side project!\nOnce again I feel grateful for Georgi Gerganov for making whisper.cpp happen, legends that maintains yt-dlp and ffmpeg, and all other open source project maintainers.\nAlso, playing around with speech recognition was a nice change of pace from the LLM slop I deal with on daily basis.\nPost 26 of #100DaysToOffload.\nThe song was “Love \u0026 Joy” by 紫雲清夏 (CV. 湊 みや). Honestly it’s just so good that I don’t enough vocabulary to describe it. ↩︎\n","wordCount":"1057","inLanguage":"en","datePublished":"2025-07-15T21:04:00+10:00","dateModified":"2025-07-15T21:04:00+10:00","author":{"@type":"Person","name":"Yosua"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://darcien.dev/p/whisper-and-joy/"},"publisher":{"@type":"Organization","name":"A blog by Yosua Ian Sebastian","logo":{"@type":"ImageObject","url":"https://darcien.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://darcien.dev/ accesskey=h title="Yosua Ian Sebastian (Alt + H)"><img src=https://darcien.dev/whale_goth.svg alt aria-label=logo height=28>Yosua Ian Sebastian</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://darcien.dev/now title=now><span>now</span></a></li><li><a href=https://darcien.dev/about title=about><span>about</span></a></li><li><a href=https://darcien.dev/uses title=uses><span>uses</span></a></li><li><a href=https://darcien.dev/archive title=archive><span>archive</span></a></li><li><a href=https://darcien.dev/tags title=tags><span>tags</span></a></li><li><a href=https://darcien.dev/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Whisper and Joy</h1><div class=post-meta><span title='2025-07-15 21:04:00 +1000 AEST'>2025-07-15</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1057 words&nbsp;·&nbsp;Yosua</div></header><div class=post-content><blockquote><p>🔖 Assumed post audience: me.
This is not a tutorial for whisper.cpp.
I am writing up my usage, and if I don&rsquo;t write it now, I&rsquo;ll never write about it.</p></blockquote><p>I want to analyze the words used in an internet radio series.
It&rsquo;s for a <a href=https://github.com/darcien/gkms>dumb side project</a>.</p><p>I already heard about <a href=https://openai.com/index/whisper/>Whisper from OpenAI</a> before.
And I finally have the justification to try it out.</p><h2 id=attempt-1---insanely-fast-whisper>Attempt 1 - insanely fast whisper<a hidden class=anchor aria-hidden=true href=#attempt-1---insanely-fast-whisper>#</a></h2><p>I don&rsquo;t remember why, but I started with <a href=https://github.com/Vaibhavs10/insanely-fast-whisper>insanely fast whisper</a> instead of the official Whisper repo.
Probably drawn in by the name, who doesn&rsquo;t like insanely fast stuff.</p><p>Attempt didn&rsquo;t last long though.
I followed the readme and used <code>pipx</code>.
And it failed on building <code>sentencepiece</code> with no clear error message.</p><p>I tried again with <code>uv tool install</code>.
It failed again on <code>sentencepiece</code>, but gave a better message around the
minimum CMake version.
Unfortunately, I already have latest CMake via Homebrew.</p><p>A quick search turned up various people, each with different setups
and different errors.</p><p>Great.</p><p>It&rsquo;s 2025 and Python ecosystem is still as messy as ever.
I didn&rsquo;t miss it at all.</p><h2 id=attempt-2---macwhisper>Attempt 2 - MacWhisper<a hidden class=anchor aria-hidden=true href=#attempt-2---macwhisper>#</a></h2><p>I found MacWhisper in a <a href=https://github.com/ggml-org/whisper.cpp/discussions/420>GH discussion</a>.
Looks like a clean and simple macOS app with no python mess, let&rsquo;s try it.</p><p>It&rsquo;s free, and I&rsquo;m grateful for that.
But oof, on start, it downloads the v3 turbo model.
It immediately runs transcription on my CPU on file selection.
And then say it says it&rsquo;s requires pro license.</p><p>100 EUR for permanent license.</p><p>Ok, time to try something else.
Sorry, not a fan of that default behavior of wasting bandwidth and CPU before asking for money.
I lost my interest even before retrying with &ldquo;free&rdquo; model.</p><h2 id=attempt-3---whispercpp>Attempt 3 - whisper.cpp<a hidden class=anchor aria-hidden=true href=#attempt-3---whispercpp>#</a></h2><p>I&rsquo;m going to start with: no dependencies is awesome.
That&rsquo;s <a href=https://github.com/ggml-org/whisper.cpp>whisper.cpp</a>.</p><p>I cheated a bit and installed via Homebrew though.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>brew install whisper-cpp
</span></span></code></pre></div><p>Next, model.
My radio series is in Japanese.
I can&rsquo;t find any mainstream JP model.
So I went with <code>large-v3-turbo</code>.</p><p>There are quantized models (q5 and q8 at the time).
But doesn&rsquo;t seem to provide any savings in my case.
I have enough RAM to load the large model (~3.9 GB) and the disk savings are &lt; 1 GB.</p><p>whisper.cpp provided <a href=https://github.com/ggml-org/whisper.cpp/blob/master/models/README.md>nice script</a> to download the model:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>./download-ggml-model.sh large-v3-turbo
</span></span></code></pre></div><p>Next, preparing the audio input.</p><h2 id=preparing-the-audio>Preparing the audio<a hidden class=anchor aria-hidden=true href=#preparing-the-audio>#</a></h2><blockquote><p>Note that the whisper-cli example currently runs only with 16-bit WAV files, so make sure to convert your input before running the tool. For example, you can use ffmpeg like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>ffmpeg -i input.mp3 -ar <span class=m>16000</span> -ac <span class=m>1</span> -c:a pcm_s16le output.wav
</span></span></code></pre></div></blockquote><p>Okay, my source is an mp4 container.
How can I convert it to WAV?</p><p>That was a dumb question.
<code>ffmpeg</code> is just too awesome, you can throw the mp4 at it directly.</p><p>So my command is exactly the same as the example from whisper.cpp.</p><h2 id=test-run-with-whispercpp>Test run with whisper.cpp<a hidden class=anchor aria-hidden=true href=#test-run-with-whispercpp>#</a></h2><p>Ooohhhh it runs on metal, literally!</p><pre tabindex=0><code>❯ whisper-cli -m ./ggml-large-v3-turbo.bin --detect-language -f housoubu/45_f5t3gjlf9we.wav
whisper_init_from_file_with_params_no_state: loading model from &#39;./ggml-large-v3-turbo.bin&#39;

...

system_info: n_threads = 4 / 10 | WHISPER : COREML = 0 | OPENVINO = 0 | Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | ACCELERATE = 1 | REPACK = 1 |

main: processing &#39;housoubu/45_f5t3gjlf9we.wav&#39; (44800341 samples, 2800.0 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = auto, task = transcribe, timestamps = 1 ...

whisper_full_with_state: auto-detected language: ja (p = 0.998406)

...

ggml_metal_free: deallocating
</code></pre><p>I&rsquo;m using <code>--detect-language</code> just for sanity check, but it&rsquo;s looking great!</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>-dl, --detect-language <span class=o>[</span>false<span class=o>]</span> <span class=nb>exit</span> after automatically detecting language
</span></span></code></pre></div><p>Onwards to the real test run!
I tested with default parameters, and the live output looks great.</p><p>Until I saw this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>[00:33:06.200 --&gt; 00:33:08.520]  シン・スミカでラブ&amp;ジョイ
</span></span><span class=line><span class=cl>[00:33:08.920 --&gt; 00:33:30.900]  さよならを告げた後悔
</span></span><span class=line><span class=cl>[00:33:30.900 --&gt; 00:33:32.900]  さよならを告げてください
</span></span><span class=line><span class=cl>[00:33:32.900 --&gt; 00:33:33.900]  さよならを告げてください
</span></span><span class=line><span class=cl>[00:33:33.900 --&gt; 00:33:34.900]  さよならを告げてください
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>[00:36:25.900 --&gt; 00:36:27.900]  さよならを告げてください
</span></span><span class=line><span class=cl>[00:36:27.900 --&gt; 00:36:29.900]  さよならを告げてください
</span></span><span class=line><span class=cl>[00:36:29.900 --&gt; 00:36:30.900]  さよならを告げてください
</span></span><span class=line><span class=cl>[00:36:30.900 --&gt; 00:36:33.900]  7月4日の公演をもって完走した
</span></span></code></pre></div><p>Looks very scary at first, like one of those horror movies where paranormal
activities start to spam you with the same message over and over.
Even more so when model changed the lyric from &ldquo;さよならを告げた 後悔&rdquo;
to &ldquo;さよならを告げてください&rdquo;.
Literally translated, it&rsquo;s &ldquo;I said goodbye. Regret&rdquo; changed to &ldquo;Please say goodbye&rdquo;.</p><p>So what I have now is:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>Please say goodbye
</span></span><span class=line><span class=cl>Please say goodbye
</span></span><span class=line><span class=cl>Please say goodbye
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>Please say goodbye
</span></span><span class=line><span class=cl>Please say goodbye
</span></span><span class=line><span class=cl>Please say goodbye
</span></span></code></pre></div><p>😱😱😱</p><p>But I already listened to that episode.
I know nobody is repeating that same sentence for 3 minutes straight.</p><p>Actual lyrics are<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>さよならを告げた 後悔
</span></span><span class=line><span class=cl>一歩ずつ前へ進んでも
</span></span><span class=line><span class=cl>まだ隠してる弱さは見せれない
</span></span></code></pre></div><p>The model did get the first sentence correct.
But the song already stopped playing at 34:50 mark.
Another sentence already started from 34:55 and it still outputs the same goodbye sentence.
So model lost track of at least ~1.5 minutes worth of conversation here.</p><p>This audio section might be a good test input while I do trial and error
with the transcription.
It shouldn&rsquo;t be censorship that prevents transcribing licensed music right?
I sure hope we&rsquo;re not at that point of dystopia yet.</p><h2 id=whats-next>What&rsquo;s next?<a hidden class=anchor aria-hidden=true href=#whats-next>#</a></h2><p>I need to optimize whisper parameters to fit my use case.
Probably manually for now since the radio episode isn&rsquo;t that long, ~46 mins each.</p><p>Also need to download only the audio part as the radio video is mostly static and irrelevant in this case.
Probably <code>yt-dlp -x</code> works here.</p><h2 id=afterthought>Afterthought<a hidden class=anchor aria-hidden=true href=#afterthought>#</a></h2><p>I&rsquo;m not sure what is this weird feeling.
The &ldquo;standing on the shoulder of giants&rdquo; feeling, maybe awe?
It&rsquo;s mindblowing that I could just piece around few open source building blocks
in a few hours, and have a working implementation for video -> audio -> text.
And it&rsquo;s for non-English content!</p><p>Few years ago, I feel like this would take me maybe months to read
and implement someone&rsquo;s PhD thesis.
I wouldn&rsquo;t have the time to do that for a dumb side project!</p><p>Once again I feel grateful for Georgi Gerganov for making whisper.cpp happen,
legends that maintains yt-dlp and ffmpeg,
and all other open source project maintainers.</p><p>Also, playing around with speech recognition was a nice change of pace from
the LLM slop I deal with on daily basis.</p><hr><p>Post 26 of <a href=https://100daystooffload.com/>#100DaysToOffload</a>.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>The song was <a href="https://www.youtube.com/watch?v=YzBr_c61TsU">&ldquo;Love & Joy&rdquo; by 紫雲清夏 (CV. 湊 みや)</a>.
Honestly it&rsquo;s just so good that I don&rsquo;t enough vocabulary to describe it.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://darcien.dev/tags/gkms/>Gkms</a></li><li><a href=https://darcien.dev/tags/100daystooffload/>100DaysToOffload</a></li></ul><nav class=paginav><a class=next href=https://darcien.dev/p/codespace-error/><span class=title>Next »</span><br><span>Error, Loneliness and Codespace</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 A blog by Yosua Ian Sebastian</span><br><span>Blog logo is a recolored <a target=_blank referrerpolicy=no-referrer rel=noopener href=https://github.com/twitter/twemoji>Spouting Whale Twemoji</a> by Twitter, Inc
and other contributors and is licensed under <a target=_blank referrerpolicy=no-referrer rel=noopener href=https://creativecommons.org/licenses/by/4.0/>CC-BY
4.0</a></span><div class=footer-blank>This space intentionally left blank.</div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>